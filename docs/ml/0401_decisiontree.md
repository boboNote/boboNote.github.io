---
layout: default
title: decisiontree
parent: classfication
grand_parent: Machine learning
permalink: /docs/ml/classification/decisiontree
nav_order: 4001
---

# decisiontree
{: .no_toc }

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## 결정트리와 앙상블 
결정트리는 매우 쉽고 유연하게 적용될 수 있는 알고리즘입니다. 또한 데이터의 스케일링이나 정규화 등의 사전 가공의 영향이 매우 적습니다. 하지만 예측 성능을 향상시키기 위해 복잡한 규칙 구조를 가져야 하며, 이로 인해 과적합(overfitting)이 발생해 예측성닝이 저하될 수도 있다는 단점이 있습니다. 
하지만 이러한 단점이 ``앙상블 기법``에서는 오히려 장점으로 작용합니다. 앙상블은 매우 많은 여러개의 ``약한 학습기``(즉 , 예측 성능이 상대적으로 떨어지는 학습 알고리즘)를 결합해 확률적 보완과 오류가 발생한 부분에 대한 가중치를 계속 업데이트 하면서 예측 성능을 향상 시키는데, 결정 트리가 좋은 약한 학습기가 되기 때문입니다.(**GBM, XGBOOST, LightGBM**)


## 결정트리 
결정 트리 알고리즘은 데이터에 있는 규칙을 학습을 통해 자동으로 찾아내 트리(Tree)기반의 분류 규칙을 만듭니다.(If-Else 기반 규칙)
따라서 데이터의 어떤 기준을 바탕으로 규칙을 만들어야 가장 효율적인 분류가 될 것인가가 알고리즘의 성능을 크게 좌우합니다. 

### 균일도 기반 규칙조건 
### 정보이득 
정보 이득은 엔트로피라는 개념을 기반으로 합니다. 엔트로피는 주어진 데이터 집합의 혼잡도를 의미하는데, 서로다른 값이 섞여 있으면 엔트로피가 높고, 같은 값이 섞여 있으면 엔트로피가 낮습니다. 정보 이득 지수는 1에서 엔트로피 지수를 뺀 값입니다. 즉, ``1-엔트로피 지수``입니다. 결정트리는 이 정보 이득 지수로 분할 기준을 정합니다. 

엔트로피 지수 != 정보이득 

**반복되는 값이 많이 있으면 반복값에 따른 기대값이 낮다.**
**반면 반복적으로 나오지않으면 기대값이 높다.**

### 지니 계수 
지니 계수는 원래 경제학에서 불평등 지수를 나타낼 때 사용하는 계수입니다. 경제학자인 코라도 지니의 이름에서 딴 계수로서 0이 가장 평등하고 1로 갈수록 불평등합니다. 머신러닝에 적용될때는 지니 계수가 낮을 수록 데이터 균일도가 높은 것으로 해석되어 계수가 낮은 속성을 기준으로 분할 합니다.

![decisiontree](../img/04_decisiontree.png)

